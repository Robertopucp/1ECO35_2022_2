vector = seq(100)
# creando función reescalar
reescalar <- function(i, min, max){
( i -  min ) / ( max - min )
}
sapply(vector, reescalar, min = min(vector), max = max(vector) )
matriz = matrix(as.integer(sample(10000,replace=F)),nrow = 100,ncol = 50)
apply(matriz, Margin=2, reescalar )
# aplicando función reescalar a la matriz
apply(matriz, MARGIN=2, reescalar )
# aplicando función reescalar a la matriz
apply(matriz, MARGIN=2, FUN=reescalar )
# aplicando función reescalar a la matriz
apply(matriz, MARGIN=2, FUN=mean )
# aplicando función reescalar a la matriz
apply(matriz, MARGIN=2, FUN=reescalar, min = min(vector), max = max(vector)  )
matriz = matrix(as.integer(sample(10000,ascendin=T,replace=F)),nrow = 100,ncol = 50)
# aplicando función reescalar a la matriz
apply(matriz, MARGIN=2, FUN=reescalar, min = min(vector), max = max(vector)  )
matriz = matrix(as.integer(seq(10000)),nrow = 100,ncol = 50)
View(matriz)
# aplicando función reescalar a la matriz
apply(matriz, MARGIN=2, FUN=reescalar, min = min(vector), max = max(vector)  )
# aplicando función reescalar a la matriz
apply(matriz, Margin=2, Fun=reescalar, min = min(vector), max = max(vector)  )  # MARGIN=2, la función se aplica por columna
# aplicando función reescalar a la matriz
apply(matriz, MARGIN=2, FUN=reescalar, min = min(vector), max = max(vector)  )  # MARGIN=2, la función se aplica por columna
pacman::p_load(tidyverse, haven, janitor, stringr )   # otra forma de cargar librerías
()
library(dplyr) # libreria de limpieza de datos
library(tidyr)
library(janitor)
"1.0 Set Directorio"
user <- Sys.getenv("USERNAME")  # username
setwd( paste0("C:/Users/",user,"/Documents/GitHub/1ECO35_2022_2") ) # set directorio
"2.0 Load dataset de la base data_administrativa"
admin <- read_sav("../../../Documents/GitHub/1ECO35_2022_2/data/data_administrativa.sav")
admin <- data.frame(
read_sav("../../../Documents/GitHub/1ECO35_2022_2/data/data_administrativa.sav")
)
View(admin)
library(dplyr) # libreria de limpieza de datos
library(tidyr)
library(janitor)
"1.0 Set Directorio"
user <- Sys.getenv("USERNAME")  # username
setwd( paste0("C:/Users/",user,"/Documents/GitHub/1ECO35_2022_2") ) # set directorio
"2.0 Load dataset de la base data_administrativa"
admin <- read_sav("../../../Documents/GitHub/1ECO35_2022_2/data/data_administrativa.sav")
admin <- data.frame(
read_sav("../../../Documents/GitHub/1ECO35_2022_2/data/data_administrativa.sav")
)
View(admin)
library(haven)
"1.0 Set Directorio"
user <- Sys.getenv("USERNAME")  # username
setwd( paste0("C:/Users/",user,"/Documents/GitHub/1ECO35_2022_2") ) # set directorio
"2.0 Load dataset de la base data_administrativa"
admin <- read_sav("../../../Documents/GitHub/1ECO35_2022_2/data/data_administrativa.sav")
admin <- data.frame(
read_sav("../../../Documents/GitHub/1ECO35_2022_2/data/data_administrativa.sav")
)
View(admin)
VARna <- apply(is.na(admin), 2, sum)>=1 #verificamos cuales variables tienen al menos un valor NA.
VARna[VARna==TRUE] #Mostramos las variables que presentan missing values
pacman::p_load(tidyverse, haven, janitor, stringr )   # otra forma de cargar librerías
user <- Sys.getenv("USERNAME")  # username
setwd( paste0("C:/Users/",user,"/Documents/GitHub/1ECO35_2022_2/Lab6") ) # set directorio
# Put relative path
file_path = "../data/data_administrativa.sav"
df <- haven::read_sav(file_path , encoding = "UTF-8" )  # read dataset
###########
# Mostrar las variables que presentan missing values
colSums(is.na(df))     # muestra el número de missing por columna
"4.0 Mostramos las etiquetas en Value labels y var labels DE ESTRATO y DOMINIO"
admin$ESTRATO %>% attr('labels') # value labels
admin$ESTRATO %>% attr('label') # var label
admin$DOMINIO %>% attr('labels') # value labels
admin$DOMINIO %>% attr('label') # var label
get_dupes(admin, CONGLOME, VIVIENDA, HOGAR, CODPERSO)
# Se le pide mostrar las etiquetas de dos variables (var labels) y las etiquetas
# de los valores en dos variables (value's labels).
df$DOMINIO %>% attr('label')  # var labels
df$ESTRATO %>% attr('label')  # var labels
df$DOMINIO %>% attr('labels') # value labels
df$ESTRATO %>% attr('labels') # value labels
###########
attach(df) # para que cada columna sea un objeto independiente y prenscindamos del data$col
duplicated_data <- df %>% group_by(CONGLOME, VIVIENDA, HOGAR, CODPERSO) %>%
mutate(duplicates = n()) %>% filter(duplicates >1) %>%
select(CONGLOME, VIVIENDA, HOGAR, CODPERSO, duplicates )
View(duplicated_data)
admin2019 <- admin %>% filter(year == 2019)
View(admin2019)
df_noduplicates <- df_noduplicates %>% arrange(year, CONGLOME, VIVIENDA, HOGAR, CODPERSO)  # libreria dplyr
###########
# Finalmente crear una base de datos para cada año y guardar en la carpeta data con los siguientes nombres
# data_2019_(numero de grupo) y data_2020_(numero de grupo).
# creando base para cada año
df_2019 <- df_noduplicates %>% filter(year == "2019")
df_2020 <- df_noduplicates %>% filter(year == "2020")
View(df_2019)
# creando base para cada año
df_2019 <- df_noduplicates %>% filter(year == "2019")
df_noduplicates <- df_noduplicates %>% arrange(year, CONGLOME, VIVIENDA, HOGAR, CODPERSO)  # libreria dplyr
# creando base para cada año
df_2019 <- df_noduplicates %>% filter(year == "2019")
# Drop duplicates rows (observaciones). Borra las copias, no las primeras apariciones.
df_noduplicates <- df %>% distinct(CONGLOME, VIVIENDA, HOGAR, CODPERSO, .keep_all = TRUE)
df_noduplicates <- df_noduplicates %>% arrange(year, CONGLOME, VIVIENDA, HOGAR, CODPERSO)  # libreria dplyr
# creando base para cada año
df_2019 <- df_noduplicates %>% filter(year == "2019")
pacman::p_load(tidyverse, haven, janitor, stringr )   # otra forma de cargar librerías
user <- Sys.getenv("USERNAME")  # username
setwd( paste0("C:/Users/",user,"/Documents/GitHub/1ECO35_2022_2/Lab6") ) # set directorio
# Put relative path
file_path = "../data/data_administrativa.sav"
df <- haven::read_sav(file_path , encoding = "UTF-8" )  # read dataset
colSums(is.na(df))     # muestra el número de missing por columna
#############
####  3  ####
# Se le pide mostrar las etiquetas de dos variables (var labels) y las etiquetas
# de los valores en dos variables (value's labels).
df$DOMINIO %>% attr('label')  # var labels
df$ESTRATO %>% attr('label')  # var labels
df$DOMINIO %>% attr('labels') # value labels
df$ESTRATO %>% attr('labels') # value labels
# Se le pide detectar personas que fueran entrevistadas en ambos años. Para ello, se pide
# detectar duplicados a partir del identificador por persona : conglome, vivienda, hogar y codperso.
attach(df) # para que cada columna sea un objeto independiente y prenscindamos del data$col
duplicated_data <- df %>% group_by(CONGLOME, VIVIENDA, HOGAR, CODPERSO) %>%
mutate(duplicates = n()) %>% filter(duplicates >1) %>%
select(CONGLOME, VIVIENDA, HOGAR, CODPERSO, duplicates )
View(duplicated_data)
# Drop duplicates rows (observaciones). Borra las copias, no las primeras apariciones.
df_noduplicates <- df %>% distinct(CONGLOME, VIVIENDA, HOGAR, CODPERSO, .keep_all = TRUE)
df_noduplicates <- df_noduplicates %>% arrange(year, CONGLOME, VIVIENDA, HOGAR, CODPERSO)  # libreria dplyr
View(df_noduplicates)
pacman::p_load(tidyverse, haven, janitor, stringr )   # otra forma de cargar librerías
user <- Sys.getenv("USERNAME")  # username
setwd( paste0("C:/Users/",user,"/Documents/GitHub/1ECO35_2022_2/Lab6") ) # set directorio
# Put relative path
file_path = "../data/data_administrativa.sav"
df <- haven::read_sav(file_path , encoding = "UTF-8" )  # read dataset
# Mostrar las variables que presentan missing values
colSums(is.na(df))     # muestra el número de missing por columna
df$DOMINIO %>% attr('label')  # var labels
df$ESTRATO %>% attr('label')  # var labels
df$DOMINIO %>% attr('labels') # value labels
df$ESTRATO %>% attr('labels') # value labels
# Se le pide detectar personas que fueran entrevistadas en ambos años. Para ello, se pide
# detectar duplicados a partir del identificador por persona : conglome, vivienda, hogar y codperso.
attach(df) # para que cada columna sea un objeto independiente y prenscindamos del data$col
duplicated_data <- df %>% group_by(CONGLOME, VIVIENDA, HOGAR, CODPERSO) %>%
mutate(duplicates = n()) %>% filter(duplicates >1) %>%
select(CONGLOME, VIVIENDA, HOGAR, CODPERSO, duplicates )
View(duplicated_data)
# Borrando duplicados. Borra las copias, no las primeras apariciones.
df_noduplicates <- df %>% distinct(CONGLOME, VIVIENDA, HOGAR, CODPERSO, .keep_all = TRUE)
df_noduplicates <- df_noduplicates %>% arrange(year, CONGLOME, VIVIENDA, HOGAR, CODPERSO)  # libreria dplyr para ordenar
# creando base para cada año
df_2019 <- df_noduplicates %>% filter(year == "2019")
View(df_2019)
df_2020 <- df_noduplicates %>% filter(year == "2020")
View(df_2020)
# guardando las bases de datos
write.csv(df_2019,"../data/data_2019_Grupo7.csv", row.names = FALSE)
write.csv(df_2020,"../data/data_2020_Grupo7.csv", row.names = FALSE)
