{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac075bb0",
   "metadata": {},
   "source": [
    "## 1) Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb6c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # for usernanme y set direcotrio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import weightedcalcs as wc # ponderador\n",
    "from tqdm import tqdm  # controlar el tiempo en un loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be6dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio \n",
    "\n",
    "user = os.getlogin()   # Username\n",
    "\n",
    "os.chdir(f\"C:/Users/{user}/Documents/GitHub/Scripts_SabinaOlivera_r_py_jl/tareas\") #directorio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c1a1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dominio', 'estrato', 'tipenc', 'result', 'panel', 'p22', 'p24a', 'p24b', 'p25_1', 'p25_2', 'p25_3', 'p25_4', 'p25_5', 'p101', 'p102', 'p103', 'p103a', 'p104b1', 'p104b2', 'p105a', 'p106a', 'p106b', 'p107b1', 'p107c11', 'p107c12', 'p107c13', 'p107c14', 'p107c16', 'p107c17', 'p107c18', 'p107c19', 'p107c110', 'p107b2', 'p107c21', 'p107c22', 'p107c23', 'p107c24', 'p107c26', 'p107c27', 'p107c28', 'p107c29', 'p107c210', 'p107b3', 'p107c31', 'p107c32', 'p107c33', 'p107c34', 'p107c36', 'p107c37', 'p107c38', 'p107c39', 'p107c310', 'p107b4', 'p107c41', 'p107c42', 'p107c43', 'p107c44', 'p107c46', 'p107c47', 'p107c48', 'p107c49', 'p107c410', 'p107e', 'p110', 'p110a1', 'p110c', 'p110d', 'p110e', 'p110f', 'p110g', 'p111a', 'p1121', 'p1123', 'p1124', 'p1125', 'p1126', 'p1127', 'p112a', 'p1131', 'p1132', 'p1133', 'p1135', 'p1136', 'p1139', 'p1137', 'p1138', 'p113a', 'p1141', 'p1142', 'p1143', 'p1144', 'p1145', 'p1171_01', 'p1171_02', 'p1171_03', 'p1171_04', 'p1171_05', 'p1171_06', 'p1171_07', 'p1171_08', 'p1171_09', 'p1171_10', 'p1171_11', 'p1171_12', 'p1171_13', 'p1171_14', 'p1171_15', 'p1171_16', 'p1175_01', 'p1175_02', 'p1175_03', 'p1175_04', 'p1175_05', 'p1175_06', 'p1175_07', 'p1175_08', 'p1175_09', 'p1175_10', 'p1175_11', 'p1175_12', 'p1175_13', 'p1175_14', 'p1175_15', 'p1175_16', 'p612i1', 'p612i2', 't110', 't111a', 'nbi1', 'nbi2', 'nbi3', 'nbi4', 'nbi5', 'ticuest01', 'tipocuestionario', 'tipoentrevista', 'rechazo_razones'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Merge 2020 ##################\n",
    "\n",
    "#Modulo 1 (Caracteristicas de vivienda y hogar)\n",
    "# Colocamos convert_categoricals=False, pues esto por deafult es True y queremos que se respete los value's label \n",
    "\n",
    "enaho01_2020 = pd.read_stata(r\"../../../enaho/2020/737-Modulo01/737-Modulo01/enaho01-2020-100.dta\",\n",
    "                           convert_categoricals=False)\n",
    "\n",
    "labels01 = pd.read_stata(r\"../../../enaho/2020/737-Modulo01/737-Modulo01/enaho01-2020-100.dta\",\n",
    "                           convert_categoricals=False, iterator=True)\n",
    "\n",
    "labels01.variable_labels()\n",
    "labels01.value_labels().keys()\n",
    "\n",
    "# Modulo 34 (sumarias)\n",
    "\n",
    "enaho34_2020 = pd.read_stata(r\"../../../enaho/2020/737-Modulo34/737-Modulo34/sumaria-2020.dta\",\n",
    "                           convert_categoricals=False)\n",
    "\n",
    "#Realizamos merge del modulo 1 y 34 del año 2020\n",
    "#identificador del hogar: conglome, vivienda, hogar\n",
    "\n",
    "merge2020= pd.merge(enaho01_2020, enaho34_2020, \n",
    "                         on = [\"conglome\", \"vivienda\", \"hogar\"],\n",
    "                       how = \"left\", \n",
    "                       validate = \"1:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275f242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Merge 2019 ##################\n",
    "\n",
    "enaho01_2019 = pd.read_stata(r\"../../../enaho/2019/687-Modulo01/687-Modulo01/enaho01-2019-100.dta\",\n",
    "                           convert_categoricals=False)\n",
    "\n",
    "enaho34_2019 = pd.read_stata(r\"../../../enaho/2019/687-Modulo34/687-Modulo34/sumaria-2019.dta\",\n",
    "                           convert_categoricals=False)\n",
    "\n",
    "\n",
    "merge2019 = pd.merge(enaho01_2019, enaho34_2019, \n",
    "                         on = [\"conglome\", \"vivienda\", \"hogar\"],\n",
    "                       how = \"left\", \n",
    "                       validate = \"1:1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e6a7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SABINA\\AppData\\Local\\Temp\\ipykernel_35548\\3416170526.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merge_append = merge2020.append(merge2019, ignore_index = True) #ignore_index= True para que no haya conflictos de indexing\n",
      "C:\\Users\\SABINA\\anaconda3\\lib\\site-packages\\pandas\\io\\stata.py:2491: InvalidColumnName: \n",
      "Not all pandas column names were valid Stata variable names.\n",
      "The following replacements have been made:\n",
      "\n",
      "    aÑo_x   ->   a_o_x\n",
      "    aÑo_y   ->   a_o_y\n",
      "\n",
      "If this is not what you expect, please make sure you have Stata-compliant\n",
      "column names in your DataFrame (strings only, max 32 characters, only\n",
      "alphanumerics and underscores, no Stata reserved words)\n",
      "\n",
      "  warnings.warn(ws, InvalidColumnName)\n"
     ]
    }
   ],
   "source": [
    "########### Append 2019 y 2020 ############\n",
    "\n",
    "merge_append = merge2020.append(merge2019, ignore_index = True) #ignore_index= True para que no haya conflictos de indexing \n",
    "\n",
    "merge_append.to_stata(\"../../../append_enaho.dta\", write_index = False) # usamos write_index=False para no guardar con una columan de index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a83ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SABINA\\AppData\\Local\\Temp\\ipykernel_35548\\2700305781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_append[\"ingreso_mensual\"] = merge_append[\"inghog1d\"]/(12*merge_append[\"mieperho\"])\n",
      "C:\\Users\\SABINA\\AppData\\Local\\Temp\\ipykernel_35548\\2700305781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_append[\"gasto_mensual\"]  = merge_append[\"gashog2d\"]/(12*merge_append[\"mieperho\"])\n"
     ]
    }
   ],
   "source": [
    "###### Creamos ingreso y gasto mensual #####\n",
    "\n",
    "merge_append[\"ingreso_mensual\"] = merge_append[\"inghog1d\"]/(12*merge_append[\"mieperho\"])\n",
    "\n",
    "merge_append[\"gasto_mensual\"]  = merge_append[\"gashog2d\"]/(12*merge_append[\"mieperho\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9364d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SABINA\\AppData\\Local\\Temp\\ipykernel_35548\\1517560721.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_append[\"ingreso_mensual_defl\"] = merge_append[\"ingreso_mensual\"] * merge_append[\"ld\"]\n",
      "C:\\Users\\SABINA\\AppData\\Local\\Temp\\ipykernel_35548\\1517560721.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_append['departamento'] = merge_append['ubigeo_x'].str[:2]\n",
      "C:\\Users\\SABINA\\AppData\\Local\\Temp\\ipykernel_35548\\1517560721.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_append['departamento6'] = merge_append['ubigeo_x'].str[:2]+\"0000\"\n"
     ]
    }
   ],
   "source": [
    "########## Deflactando las variables ###########\n",
    "\n",
    "# El deflactor espacial es ld. \n",
    "\n",
    "merge_append[\"ingreso_mensual_defl\"] = merge_append[\"ingreso_mensual\"] * merge_append[\"ld\"]\n",
    "\n",
    "merge_append[\"gasto_mensual\"]  = merge_append[\"gasto_mensual\"]* merge_append[\"ld\"]\n",
    "\n",
    "\n",
    "#Creamos la variable \"departamento\" a partir del ubigeo para luego aplicar el merge con deflactores_2020\n",
    "\n",
    "merge_append['departamento'] = merge_append['ubigeo_x'].str[:2]\n",
    "merge_append['departamento6'] = merge_append['ubigeo_x'].str[:2]+\"0000\"\n",
    "\n",
    "merge_append = merge_append[merge_append.departamento.isin([\"15\",\"03\",\"04\"])]\n",
    "\n",
    "deflactores_base2020_new = pd.read_stata(r\"../../../enaho/2020/737-Modulo34/737-Modulo34/ConstVarGasto-Metodologia actualizada/Gasto2020/Bases/deflactores_base2020_new.dta\",\n",
    "                           convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c9ee92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and float32 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Merge entre merge_append y el deflactor temporal:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m merge_def_temporal_2020 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_append\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeflactores_base2020_new\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdepartamento\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maÑo_x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdpto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maniorec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1:1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:704\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1257\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1253\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1254\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1255\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1256\u001b[0m     ):\n\u001b[1;32m-> 1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and float32 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "#Merge entre merge_append y el deflactor temporal:\n",
    "    \n",
    "merge_def_temporal_2020 = pd.merge(merge_append, deflactores_base2020_new , \n",
    "                         left_on = [\"departamento\", \"aÑo_x\"],\n",
    "                         right_on = [\"dpto\",\"aniorec\"],\n",
    "                       how = \"left\", \n",
    "                       validate = \"1:1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c46ee4a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merge_def_temporal_2020' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#  Ingreso per capita mensual\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m merge_append[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mingreso_mensual_pc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merge_append[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minghog1d\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m12\u001b[39m\u001b[38;5;241m*\u001b[39mmerge_append[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmieperho\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mmerge_append[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mld\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[43mmerge_def_temporal_2020\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi00\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Gasto per capita mensual\u001b[39;00m\n\u001b[0;32m      7\u001b[0m merge_append[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgasto_mensual_pc\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;241m=\u001b[39m merge_append[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgashog2d\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m12\u001b[39m\u001b[38;5;241m*\u001b[39mmerge_append[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmieperho\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mmerge_append[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mld\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mmerge_def_temporal_2020[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi00\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merge_def_temporal_2020' is not defined"
     ]
    }
   ],
   "source": [
    "#  Ingreso per capita mensual\n",
    "\n",
    "merge_append[\"ingreso_mensual_pc\"] = merge_append[\"inghog1d\"]/(12*merge_append[\"mieperho\"]*merge_append[\"ld\"]*merge_def_temporal_2020[\"i00\"])\n",
    "\n",
    "# Gasto per capita mensual\n",
    "\n",
    "merge_append[\"gasto_mensual_pc\"]  = merge_append[\"gashog2d\"]/(12*merge_append[\"mieperho\"]*merge_append[\"ld\"]*merge_def_temporal_2020[\"i00\"])\n",
    "\n",
    "\n",
    "\n",
    "# inghog1d: ingreso anual del hogar \n",
    "# gashog2d: gasto anual del hogar\n",
    "# mieperho: integrantes del hogar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a7c8a",
   "metadata": {},
   "source": [
    "## 2) Salario por hora del trabajador dependiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b75deb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2010185735.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [11]\u001b[1;36m\u001b[0m\n\u001b[1;33m    convert_categoricals=False, iterator=True)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!pip install weightedcalcs\n",
    "\n",
    "import os # for usernanme y set direcotrio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import weightedcalcs as wc # ponderador\n",
    "from tqdm import tqdm  # controlar el tiempo en un loop\n",
    "\n",
    "\n",
    "user = os.getlogin()   # Username\n",
    "\n",
    "\" Read Stata dataset usando pandas\"\n",
    "\n",
    "os.chdir(f\"C:/Users/{user}/Documents/Documentos/Enaho\") # Set directorio\n",
    "\n",
    "\n",
    "enaho_2020modulo5 = pd.read_stata(r\"../../../737-Modulo05/Enaho01A-2020-500.dta\")\n",
    "\n",
    "\"Debemos colocar convert_categoricals=False. Esto por deafult es True\"\n",
    "enaho_2020modulo5 = pd.read_stata(r\"../../../737-Modulo05/Enaho01A-2020-500.dta\",\n",
    "                           convert_categoricals=False)\n",
    "\n",
    "\n",
    "labels01 = pd.read_stata((r\"../../../737-Modulo05/Enaho01A-2020-500.dta\",\n",
    "                           convert_categoricals=False, iterator=True)\n",
    "                         \n",
    "\"Elegimos la base de datos como Master Data: módulo 05:\n",
    "\n",
    "enaho_2020modulo5 = pd.read_stata(r\"../../../737-Modulo05/Enaho01A-2020-500.dta\",\n",
    "                           convert_categoricals=False)\n",
    "\n",
    "## Filter ##\n",
    "\n",
    "index_columns = np.where(enaho_2020modulo5.columns.str.contains('i524e1', regex=True))[0]\n",
    "index_columns = np.where(enaho_2020modulo5.columns.str.contains('i538e1', regex=True))[0]\n",
    "index_columns = np.where(enaho_2020modulo5.columns.str.contains('i513t', regex=True))[0]\n",
    "index_columns = np.where(enaho_2020modulo5.columns.str.contains('i518', regex=True))[0]\n",
    "\n",
    "\n",
    "#Replace missing values\n",
    "\n",
    "enaho_2020modulo5[\"i524e1\"].replace({0: np.nan}, inplace =True)\n",
    "enaho_2020modulo5[\"i538e1\"].replace({0: np.nan}, inplace =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d89f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen urbano variable\n",
    "\n",
    "enaho_2020modulo5[\"ingreso\"] = i524e1 + i538e1\n",
    "enaho_2020modulo5[\"horasen_principal_y_2do_empleo\"] = i513t + i518\n",
    "enaho_2020modulo5[\"salario\"] = ingreso/(horasen_principal_y_2do_empleo*52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8549abba",
   "metadata": {},
   "source": [
    "## 3) Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weightedcalcs\n",
    "import os   # for usernanme y set direcotrio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import weightedcalcs as wc # ponderador\n",
    "from tqdm import tqdm  # controlar el tiempo en un loop\n",
    "\n",
    "#Extraemos la data del modulo 2\n",
    "user = os.getlogin()   # Username\n",
    "\n",
    "\n",
    "os.chdir(f\"C:/Users/{user}/Documents/GitHub/1ECO35_2022_2/Lab7\") # Set directorio\n",
    "\n",
    "\n",
    "enaho02 = pd.read_stata(r\"../../../datos/2020/737-Modulo02/737-Modulo02/enaho01-2020-200.dta\",\n",
    "                           convert_categoricals=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamos por hogar y vemos la edad máxima del hogar \n",
    "base2 = enaho02.groupby( [ \"conglome\", \"vivienda\", \"hogar\" ],\n",
    "                              as_index = False ).agg( edad_max = ( 'p208a', np.max ))\n",
    "\n",
    "#Extraemos la data del modulo 34\n",
    "\n",
    "enaho34 = pd.read_stata(r\"../../../datos/2020/737-Modulo34/737-Modulo34/sumaria-2020.dta\",\n",
    "                           convert_categoricals=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c762f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identificador por hogar: conglome, vivienda, hogar\n",
    "\n",
    "enaho_merge = pd.merge(base2, enaho34,\n",
    "                       on = [\"conglome\", \"vivienda\", \"hogar\"],\n",
    "                       how = \"left\", \n",
    "                       validate = \"m:1\", suffixes=('', '_y'))\n",
    "\n",
    "#Creamos la dummy\n",
    "base2[\"dummy_pension\"] = np.where(\n",
    "    enaho_merge[\"edad_max\"] <=65 ,1, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
