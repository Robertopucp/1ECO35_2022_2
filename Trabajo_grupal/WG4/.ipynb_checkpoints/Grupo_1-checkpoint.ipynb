{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7391ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#%% Grupo 1. Miembros del grupo:\n",
    "\n",
    "# 20163197, Enrique Alfonso Pazos \n",
    "# 20191894, Ilenia Ttito\n",
    "# 20151595, Rodrigo Ramos\n",
    "# 20193469, Luis Egusquiza \n",
    "# 20163377, Jean Niño de Guzmán\n",
    "\n",
    "    #%% \n",
    "import os\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = os.getlogin()   # Usuario del dispositivo\n",
    "os.chdir(f\"C:/Users/{user}/Documentos/GitHub/1ECO35_2022_2/data\") # Definimos el directorio\n",
    "\n",
    "# Leemos el archivo de Workspace R \n",
    "dr = pyreadr.read_r(\"../data/cps2012.Rdata\")\n",
    "\n",
    "# Convertimos en un dataframe\n",
    "dr = dr['data'] \n",
    "\n",
    "\n",
    "#Filtando la base de datos\n",
    "# Saca la varianza de cada vector y lo pasa a un array\n",
    "var_cols = dr.var().to_numpy()\n",
    "\n",
    "# Se filtran las columnas con valores constantes (muchos 1), nos aseguramos de tener variables continuas\n",
    "\n",
    "df = dr.iloc[:,np.where(var_cols != 0)[0]]\n",
    "X = df.iloc[:,1:10] # Filtra por posiciones\n",
    "y = df[['lnw']] # Filtra por el nombre de la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Parte 1\n",
    "\n",
    "class RegClass( object ):\n",
    "    \n",
    "    #Se definen X como un data frame y Y como una serie, y se indica que en este caso si habrá intercepto\n",
    "    def __init__( self, X : pd.DataFrame , y : pd.Series , intercept = True  ):\n",
    "    \n",
    "        #Creación de atributos de acuerdo a la base de datos (añadiendo intercepto)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.intercept = intercept\n",
    "        \n",
    "        #Se indica que se apliquen las funciones si se cuenta con intercepto, y en caso contrario no hacer nada\n",
    "        if self.intercept:\n",
    "\n",
    "            self.X[ 'Intercept' ] = 1\n",
    "            #Coloación del Intercepto como la primera columna\n",
    "            cols = self.X.columns.tolist() # nombre de varaible a lista \n",
    "            new_cols_orders = [cols[ -1 ]] + cols[ 0:-1 ] # Se juntan las listas \n",
    "            self.X = self.X.loc[ : , new_cols_orders ] # usamos .loc que filtra por nombre de filas o columnas \n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # Creación de nuevos atributos \n",
    "        \n",
    "        self.X_np = self.X.values  # Dataframe a multi array\n",
    "        self.y_np = y.values.reshape( -1 , 1 ) # de objeto serie a array columna \n",
    "        self.columns = self.X.columns.tolist() # nombre de la base de datos como objeto lista\n",
    "        \n",
    "        \n",
    "    def reg_beta_OLS( self ):\n",
    "        \n",
    "        #Se llaman a los atributos antes creados para el cálculos de los betas con a matriz X y la columna y\n",
    "        X_np = self.X_np\n",
    "        y_np = self.y_np\n",
    "        \n",
    "        \n",
    "        #Estimación de los Betas\n",
    "        beta_ols = np.linalg.inv( X_np.T @ X_np ) @ ( X_np.T @ y_np )\n",
    "\n",
    "        #Se llama al atributos de las columnas antes creado para hacer un dataframe con los betas estimados\n",
    "        index_names = self.columns\n",
    "        \n",
    "        #Se crea un dataframe con los betas estimados de cada variable en la columna y\n",
    "        beta_OLS_output = pd.DataFrame( beta_ols , index = index_names , columns = [ 'Coef.' ] )\n",
    "        \n",
    "        #Se pone el vector de coeficientes estimados como un atributo\n",
    "        self.beta_OLS = beta_OLS_output\n",
    "        \n",
    "        return beta_OLS_output\n",
    "    \n",
    "#%% Parte 2\n",
    "\n",
    "    def reg_var_OLS( self ):\n",
    "        #Se llaman a los betas calculados anteriormente\n",
    "        self.reg_beta_OLS()\n",
    "        \n",
    "        #Se crean nuevos valores y atributos para el calculos de la varianza \n",
    "        X_np = self.X_np\n",
    "        y_np = self.y_np\n",
    "        \n",
    "        \n",
    "        # Se traen los valores estimados de los betas \n",
    "        beta_OLS = self.beta_OLS.values.reshape( - 1, 1 ) \n",
    "\n",
    "        # Calculos de los errores\n",
    "        e = y_np - ( X_np @ beta_OLS )#############################################################\n",
    "        \n",
    "        # creo el atributo error porque me servirá más adelante\n",
    "        self.error = e ################################################################\n",
    "        \n",
    "        # Calculo de la varianza de los errores. \n",
    "        N = X_np.shape[ 0 ] \n",
    "        \n",
    "        total_parameters = X_np.shape[ 1 ]\n",
    "        error_var = ( (e.T @ e)[ 0 ] )/( N - total_parameters )\n",
    "\n",
    "        # Se calculan las varianzas y covarianzas\n",
    "        var_OLS =  error_var * np.linalg.inv( X_np.T @ X_np )\n",
    "\n",
    "        #Se trae el atributo de columnas antes creado para añadirlo al nuevo dataframe\n",
    "        index_names = self.columns\n",
    "        \n",
    "        #Se coloca en un dataframe las varianzas de todas las variables así y su respectiva covarianza \n",
    "        var_OLS_output = pd.DataFrame( var_OLS , index = index_names , columns = index_names )\n",
    "        \n",
    "        #Se pone la matriz de varianzas y covarianza como un atributo con los valores en el dataframe calculado antes\n",
    "        self.var_OLS = var_OLS_output\n",
    "        \n",
    "        return var_OLS        \n",
    "       \n",
    "    def reg_OLS( self ):\n",
    "        \n",
    "        # Se llaman los betas y varianzas estimados anteriormente\n",
    "        self.reg_beta_OLS()\n",
    "        self.reg_var_OLS()\n",
    "        \n",
    "        #Se llama a un atributo antes creado de X\n",
    "        X = self.X_np\n",
    "        \n",
    "        #Se traen los valores antes calculados en los dos métodos anteriores (Betas y Varianza)\n",
    "        beta_OLS = self.beta_OLS.values.reshape( -1, 1 )\n",
    "        var_OLS = self.var_OLS.values\n",
    "        \n",
    "        #Creación de los errores estándar \n",
    "        beta_se = np.sqrt( np.diag( var_OLS ) )\n",
    "        \n",
    "        # Se calcula el test statistic para cada coeficiente para poder calcular los intervalos de confianza\n",
    "        t_stat = beta_OLS.ravel() / beta_se.ravel()\n",
    "\n",
    "        #Creación del p-value para creación de intervalos de confianza\n",
    "        N = X.shape[ 0 ]\n",
    "        k = beta_OLS.size\n",
    "        pvalue = (1 - t.cdf(t_stat, df= N - k) ) * 2\n",
    "        # defining index names\n",
    "        index_names = self.columns\n",
    "       \n",
    "\n",
    "        # Creación de los intervalos de confianza de acuerdo a los betas estimados\n",
    "        \n",
    "        int1 = beta_OLS.ravel() + 1.96*beta_se\n",
    "        int2 = beta_OLS.ravel() - 1.96*beta_se\n",
    "\n",
    "        table_data ={  'Coef.'    : beta_OLS.ravel() , \n",
    "                       \"Std.Err.\" : beta_se.ravel(),\n",
    "                       \"t\"        : t_stat.ravel(),\n",
    "                       \"P>|t|\"    : pvalue.ravel(), \n",
    "                       \"[0.025\"   : int1.ravel(),\n",
    "                       \"0.975]\"   : int2.ravel()\n",
    "                    }\n",
    "        \n",
    "        # defining a pandas dataframe \n",
    "        reg_OLS = pd.DataFrame( table_data , index = index_names )\n",
    "\n",
    "        return reg_OLS  \n",
    "    \n",
    " #%% Parte 3 \n",
    "    def pregunta_3_var_covar_robust( self ):\n",
    "    \n",
    "        X = self.X_np\n",
    "            \n",
    "        \"\"\"\n",
    "        De manera más fácil sería llamar al error como atributo calculado en la función anterior\n",
    "        \"\"\"\n",
    "        # Necesito el atributo error (e)\n",
    "        self.reg_var_OLS\n",
    "        e = self.error\n",
    "        \n",
    "        # Número de observaciones = N\n",
    "        N = X.shape[ 0 ] \n",
    "        \n",
    "        # Matriz Varianza-Covarianza robusta: (X'X)^-1 * X' * Matriz_White * X * (X'X)^-1         \n",
    "        \n",
    "        # Matriz propuesta por White: error^2 * M.Identidad(MxM)\n",
    "        # Para crearla, primero debo crear una matriz de paso: e x e'\n",
    "        Matriz_de_paso = e @ e.T\n",
    "        \n",
    "        # En caso de que hubiera 4 observaciones:\n",
    "        # e1^2 e1e2 e1e3 e1e4 \n",
    "        # e2e1 e2^2 e2e3 e2e4 \n",
    "        # e3e1 e3e2 e3^2 e3e4 \n",
    "        # e4e1 e4e2 e4e3 e4^2\n",
    "        \n",
    "        # Ahora, debo diagonalizarla: \n",
    "        \n",
    "        lista = np.arange(N)\n",
    "        for i in lista:\n",
    "            for j in lista: \n",
    "                if(i == j): \n",
    "                    Matriz_de_paso[i][j] = Matriz_de_paso[i][j]\n",
    "                else:\n",
    "                    Matriz_de_paso[i][j] = 0\n",
    "        \n",
    "        # De esa manera, obtendría la matriz de White\n",
    "        # e1^2   0   0    0 \n",
    "        #  0   e2^2  0    0 \n",
    "        #  0     0  e3^2  0 \n",
    "        #  0     0   0   e4^2\n",
    "        Matriz_White = Matriz_de_paso\n",
    "        \n",
    "        # Ahora, calcularé la matriz robusta: \n",
    "        # Primero, (X'X)^-1\n",
    "        Inversa = np.linalg.inv( X.T @ X )\n",
    "        \n",
    "        # (X'X)^-1 * X' * Matriz_White * X * (X'X)^-1         \n",
    "        var_OLS_robusta = Inversa @ X.T @ Matriz_White @ X @ Inversa\n",
    "        \n",
    "        # Crearé un atributo con el valor de la matriz var-covar robusta.\n",
    "        self.var_robust = var_OLS_robusta\n",
    "\n",
    "        # Nombres de las columnas\n",
    "        index_names = self.columns\n",
    "        \n",
    "        var_robusta = pd.DataFrame(var_OLS_robusta , index = index_names , columns = index_names )\n",
    "        \n",
    "        #return var_robusta\n",
    "        return var_robusta\n",
    "\n",
    "    def pregunta_3_parte_2( self ):\n",
    "     \n",
    "        # Los atributos de las funciones anteriores\n",
    "        self.reg_beta_OLS()\n",
    "        self.pregunta_3_var_covar_robust\n",
    "        \n",
    "        # X tomará el valor del atributo X_np\n",
    "        X = self.X_np\n",
    "        \n",
    "        # La variable beta_OLS tomará los valores del output anterior transformado, aqui, a vector fila.\n",
    "        beta_OLS = self.beta_OLS.values.reshape( -1, 1 )\n",
    "        \n",
    "        # La variable var_robust será igual al output de la función anterior \n",
    "        var_robust = self.var_robust\n",
    "        \n",
    "        \"\"\"\n",
    "        OJO: voy a calcular la desviación estándar con la matriz de var-covar robusta:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Desviación estándar de los coeficientes estimados: (var(beta^))^0.5\n",
    "        beta_desv_std = np.sqrt( np.diag( var_robust ) )\n",
    "\n",
    "        N = X.shape[ 0 ] # Número de observaciones\n",
    "        k = X.shape[ 1 ] # Número de regresores\n",
    "    \n",
    "        # Intervalos de confianza:\n",
    "        \n",
    "        # t_tabla -> Distribución T-Student al 95% de confianza.\n",
    "        # bound = Desv. Estandar*t_tabla\n",
    "        bound = beta_desv_std * stats.t.ppf( ( 1 + 0.95 ) / 2., N - k )\n",
    "        \n",
    "        # Límite superior =  Coeficiente + Desv. Estandar*t_stat\n",
    "        lim_sup_robust = beta_OLS.ravel() + bound\n",
    "        \n",
    "        # Límite superior =  Coeficiente - Desv. Estandar*t_stat\n",
    "        lim_inf_robust = beta_OLS.ravel() - bound   \n",
    "    \n",
    "        \n",
    "        tabla = { 'desv. std. robusto' : beta_desv_std.ravel(),\n",
    "                  'límite superior robusto' : lim_sup_robust.ravel(),\n",
    "                  'límite inferior robusto' : lim_inf_robust.ravel()}\n",
    "        \n",
    "        # defining index names\n",
    "        index_names = self.columns\n",
    "       \n",
    "        resultados_robustos = pd.DataFrame(tabla, index = index_names )\n",
    "\n",
    "        return resultados_robustos\n",
    "    \n",
    "#%% Parte 4\n",
    "    \n",
    "    def rmse(self):\n",
    "        \n",
    "        self.reg_beta_OLS()\n",
    "        \n",
    "        #Se crean nuevos valores y atributos para el calculos de la varianza \n",
    "        X_np = self.X_np\n",
    "        y_np = self.y_np\n",
    "        \n",
    "        # Se traen los valores estimados de los betas \n",
    "        beta_OLS = self.beta_OLS.values.reshape( - 1, 1 ) \n",
    "\n",
    "        # Calculos de los errores\n",
    "        e = y_np - ( X_np @ beta_OLS )\n",
    "        \n",
    "        suma = 0 \n",
    "         \n",
    "        for v in self.y_np:\n",
    "            suma = suma + v\n",
    "        \n",
    "        media = suma/len(self.y_np)\n",
    "        \n",
    "        #columna = self.y_np\n",
    "        \n",
    "        columna = np.ones(len(self.y_np))\n",
    "        \n",
    "        y_dif= self.y_np - media * columna.T \n",
    "        \n",
    "        sct = y_dif.T @ y_dif\n",
    "                \n",
    "        sce = e.T @ e\n",
    "        \n",
    "        R_2 = 1- (sce / sct)\n",
    "        self.R_cuadrado = R_2\n",
    "        \n",
    "        root = pow(sct/len(self.y_np), 0.5)\n",
    "        self.root_mse = root\n",
    "        \n",
    "        \n",
    "        R_2_root = {'R^2': R_2.ravel(), \n",
    "                    'Root' :root.ravel()}\n",
    "        \n",
    "        index_names = self.columns\n",
    "        resultados = pd.DataFrame(R_2_root, index = index_names )\n",
    "\n",
    "        return resultados\n",
    "#%% Parte 5\n",
    "      \n",
    "    def mostrar_resultados (self):\n",
    "\n",
    "    #Corremos las funciones pertinentes\n",
    "        self.reg_OLS()\n",
    "        self.pregunta_3_var_covar_robust()\n",
    "        self.pregunta_3_parte_2()\n",
    "        self.rmse()\n",
    "    \n",
    "    # Generamos los resultados de los coeficientes estimados, errores estándar e intervalos de confianza, el R2 y el RMSE\n",
    "        result_df ={  'Coef.'     : self.beta_OLS.flatten(), \n",
    "                      'desv. std. robusto' : self.beta_desv_std.flatten(),\n",
    "                      'límite superior robusto' : self.lim_sup_robust.flatten(),\n",
    "                      'límite inferior robusto' : self.lim_inf_robust.flatten()\n",
    "             }\n",
    "    # defining index names\n",
    "        index_names = self.columns\n",
    "        \n",
    "    # Definimos estos dentro de un dataframe\n",
    "        OLS_results = pd.DataFrame( result_df , index = index_names )\n",
    "        return OLS_results\n",
    "    \n",
    "    # Creamos un diccionario que muestra todos los resultados\n",
    "    \n",
    "        final_results ={\"OLS\": OLS_results , \"R_2\" : self.R_cuadrado.flatten() ,\n",
    "                                    \"Root-MSE\" : self.R_2_root.flatten()}\n",
    "\n",
    "        return final_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
